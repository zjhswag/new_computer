X_train, y_train = make_blobs(n_samples=m, centers=centers, cluster_std=std,random_state=30)  # 得到数据集群


均方误差 (MSE): 8.966776513175452
均方根误差 (RMSE): 2.9944576325564287
决定系数 (R² Score): 0.7016044731117159


xx, yy = np.meshgrid(x0_space,x1_space) # 得到网格，如xx(x0.shape,x1.shape)，xx每一行的数据相同


ax.contour(x, y, z, linewidths=1) 搭配meshgrid,X, Y: 二维数组，分别代表等高线图的X和Y坐标点。通常与Z数组的维度相匹配。 Z: 二维数组，表示每个(X, Y)点的高度或值。这是绘制等高线所必需的。

使用np.where：
python
Copy code
idx = np.where(y == i)
这行代码执行后，idx将是一个元组，其内容是满足条件（即值等于2）的元素索引。

返回值示例：
假设上述代码执行后，你可能会得到以下结果：
python
Copy code
(array([1, 3, 7]),)
这表示在y数组中，索引1、3和7处的元素值等于2。换句话说，y[1]、y[3]和y[7]是我们要找的类别2的元素。


解读返回值：
索引数组：np.where返回的是一个元组，其第一个元素是一个数组，包含所有满足条件的元素的索引。在一维数组的情况下，你通常只需要这第一个元素。
使用索引：你可以使用这些索引来访问或操作y中相应的元素。例如，y[idx]将返回所有类别为2的元素。
np.argmax 是NumPy库中的一个函数，用于找出数组中元素的最大值的索引。简单来说，它返回的是数组中最大元素的位置。
arr = np.array([[1, 3], [2, 7]])
index_of_max_along_axis0 = np.argmax(arr, axis=0)
# 返回 [2, 7]，因为每列的最大值分别在第二行
index_of_max_along_axis1 = np.argmax(arr, axis=1)
# 返回 [3, 7]，因为每行的最大值分别在第二列,返回每行最大值


np.maximum(0, (np.dot(x, W[:, i]) + b[i])) 类似于relu层


layer_outputs = model.get_layer('L1').output
intermediate_model = Model(inputs=model.input, outputs=layer_outputs)
# 使用新模型对输入数据X_train进行预测
L1_output = intermediate_model.predict(X_train)
# 打印"L1"层的输出
# print(L1_output.shape)


SparseCategoricalCrossentropy:
适用场景: 当你的标签是整数形式时，这种形式通常用于表示类的索引。例如，如果你有三个类别，那么它们可能被表示为0, 1, 和2。
工作原理: 这种损失函数直接接受整数形式的标签，并在内部将其转换为一个独热编码形式，然后计算损失。这种方法在处理大量类别时更有效，因为它避免了手动创建大型独热编码标签数组的需要。
CategoricalCrossentropy:
适用场景: 当你的标签以独热编码（one-hot encoding）形式提供时，也就是说每个标签是一个与类别数量相同长度的数组，其中一个元素为1其余为0。例如，对于三个类别，第一个类别可能表示为[1, 0, 0]，第二个为[0, 1, 0]，依此类推。
工作原理: 这种损失函数接受独热编码的标签，并直接与预测值（通常经过softmax函数处理的概率分布）进行比较来计算损失。


reshape()函数: 这是一个用来改变数组形状的函数。你提供新的形状参数，函数就会尝试将数组重新组织成那个形状，而不改变其数据。
参数 (1, -1): 这里有两个参数，分别是1和-1。
1: 这意味着你想要新的形状有一个维度是1。在很多情况下，这表示你想要将数据变成一个单行（如果是2D的情况）。例如，如果你有一个长度为10的一维数组，reshape(1, -1)会将其变成一个1行10列的二维数组。
-1: 这是一个特殊的值，它告诉函数：“你来决定这个维度的大小。”函数将自动计算这个维度的大小，以使总元素数量与原数组相同。这意味着-1的位置会被自动计算出的值替换，以确保新形状的元素总数与原始数组一致


ax.imshow可以将一个二维数组或矩阵显示为图像。如果数组是三维的，则假定是RGB或RGBA颜色格式。
显示数据：它不仅用于显示标准图像，也常用于显示科学数据的热图，例如显示二维函数的值。
关键参数：
X：要显示的图像或数组。它可以是二维灰度格式或三维RGB/RGBA格式。
cmap：颜色映射（colormap）。用于将标量数据映射到颜色的规则，例如 'viridis'、'gray' 等。
aspect：控制图像的纵横比，例如 'auto'、'equal' 或数字。
interpolation：插值方法。定义了当像素点不足以覆盖显示区域时，如何决定区域颜色的规则，如 'nearest'、'bilinear'。
norm：用于数据标准化的实例。可以调整数据的亮度范围等。


plt.plot(history.history['val_loss']
model.fit()函数来训练模型时，history对象是该函数返回的一个记录。它包含了训练过程中的一系列有用信息，通常用于后续的分析和可视化。具体来说，history对象包含以下信息：
1. 训练损失 (loss):
这是在整个训练数据集上计算的损失函数的值，通常是每个epoch结束时计算的平均值。损失值是优化过程中试图最小化的主要指标，它反映了模型在训练集上的表现。
2. 验证损失 (val_loss):
如果在fit()函数中提供了验证数据（通过validation_data参数），那么history对象也会包含在这些验证数据上计算的损失值。这有助于监控模型在未见过的数据上的表现，检查过拟合等问题。
3. 训练准确度 (accuracy):
对于分类问题，history通常还包含准确度指标，即模型正确分类样本的比例。这是通过设置model.compile()中的metrics=['accuracy']来启用的。
4. 验证准确度 (val_accuracy):
类似于验证损失，如果你有验证数据，你也会得到模型在每个epoch结束时在验证数据上的准确度。
使用history对象:
你可以像使用字典一样使用history对象来访问这些信息。例如：
history.history['loss'] 将返回一个包含每个epoch的训练损失的列表。
history.history['val_loss'] 将返回一个包含每个epoch的验证损失的列表（如果有验证数据的话）。
可视化训练过程:
history对象通常用于绘制训练和验证损失/准确度随epoch变化的图表。这可以帮助你理解模型在训练过程中的表现，判断是否出现过拟合或欠拟合，以及决定是否需要调整学习率、增加正则化等。